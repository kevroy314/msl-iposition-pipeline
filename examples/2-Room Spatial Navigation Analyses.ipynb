{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Room Spatial Navigation Analyses\n",
    "\n",
    "This document contains a demonstration of how to analyse and visualize the 2-Room Spatial Navigation data.\n",
    "\n",
    "Note that this contains parsing and analysis code, and it is a very flexible format. It is NOT recommended that you use the cogrecon.core.data_flexing_spatial_navigation package for the 2-Room version of the Spatial Navigation Task. There are several critical differences between the tasks which would result in incorrect analysis using that library. Instead, we'll just do it all in this notebook. One exception to this recommendation is when searching for files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll list some key parameters of our task - namely, the location of the data, the names of the items which were used, and the minimum number of expected trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'Z:\\Kelsey\\2017 Summer RetLu\\Virtual_Navigation_Task\\v5_2\\NavigationTask_Data\\Logged_Data'\n",
    "study_labels = ['PurseCube', 'CrownCube', 'BasketballCube', 'BootCube', 'CloverCube', 'GuitarCube', 'HammerCube', 'LemonCube', 'IceCubeCube', 'BottleCube']\n",
    "locations = [[8, -8], [-2, -23], [8, -38], [-14, -13], [15, -18], [-14, 7], [-14, 27], [-6, 18], [8, 22], [11, 5]]\n",
    "correct_locations = {l: p for l, p in zip(study_labels, locations)}\n",
    "min_num_trials = 4\n",
    "iposition_directory = './saved_data/2-room-iposition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block of code finds and sorts the data files into \"individuals\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogrecon.core.data_flexing.spatial_navigation.spatial_navigation_parser import catalog_files\n",
    "import os\n",
    "\n",
    "files = []\n",
    "for walk_root, walk_dirs, walk_files in os.walk(data_path):\n",
    "    for f in walk_files:\n",
    "        files.append(os.path.join(walk_root, f))\n",
    "individuals, excluded, non_matching = catalog_files(files, min_num_trials)\n",
    "\n",
    "print('{0} individuals found.'.format(len(individuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the summary files can be read individually and the results aggrigated into the 'test_results' object and save the data to the iPosition data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "if not os.path.exists(iposition_directory):\n",
    "    os.makedirs(iposition_directory)\n",
    "\n",
    "count = 1\n",
    "num_items = len(study_labels)\n",
    "test_results = {}\n",
    "for individual in individuals:\n",
    "    individual_result = []\n",
    "    logging.info(\"Parsing Individual %s (%d/%d).\" % (individual.subject_id, count, len(individuals)))\n",
    "    count += 1\n",
    "    trial_count = 1\n",
    "    out_lines = []\n",
    "    for trial in individual.trials:\n",
    "        item_locations = {l: [0.0, 0.0] for l in study_labels}\n",
    "        items_found = {l: False for l in study_labels}\n",
    "        if trial.test_vr is None:\n",
    "            continue\n",
    "        with open(trial.test_vr, 'rb') as fp:\n",
    "            lines = fp.readlines()\n",
    "            lines.reverse()\n",
    "            for line in lines:\n",
    "                decoded_line = line.decode('ascii')\n",
    "                if decoded_line.startswith('Object_Identity_Set'):\n",
    "                    split_line = decoded_line.split(',')\n",
    "                    name, location_string = decoded_line[20:].strip().split(' : ')\n",
    "                    x, y, z = [float(a) for a in location_string[1:-1].split(',')]\n",
    "                    if not items_found[name]:\n",
    "                        items_found[name] = True\n",
    "                        item_locations[name] = [x, z]\n",
    "        item_location_list = list(np.array([item_locations[l] for l in study_labels]).flatten())\n",
    "        out_lines.append('\\t'.join([str(a) for a in item_location_list]))\n",
    "        individual_result.append(item_locations)\n",
    "    with open(os.path.join(iposition_directory, '{0}position_data_coordinates.txt'.format(individual.subject_id)), 'w') as fp:\n",
    "        for line in out_lines:\n",
    "            fp.write(line + '\\n')\n",
    "    test_results[individual.subject_id] = individual_result\n",
    "\n",
    "# Save actual_coordinates.txt\n",
    "item_location_list = list(np.array(locations).flatten())\n",
    "out_line = '\\t'.join([str(a) for a in item_location_list])\n",
    "with open(os.path.join(iposition_directory, 'actual_coordinates.txt'.format(individual.subject_id)), 'w') as fp:\n",
    "    for _ in range(0, min_num_trials):\n",
    "        fp.write(out_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll get the iPosition output for the converted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogrecon.core.batch_pipeline import batch_pipeline\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "batch_pipeline(iposition_directory,\n",
    "               datetime.datetime.now().strftime(\"Holodeck 2-Room Spatial Navigation - %Y-%m-%d_%H-%M-%S.csv\"), \n",
    "               trial_by_trial_accuracy=False, collapse_trials=False, actual_coordinate_prefixes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Participant\n",
    "\n",
    "Next, we can visualize an individual participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogrecon.core.data_structures import ParticipantData, AnalysisConfiguration\n",
    "from cogrecon.core.full_pipeline import full_pipeline\n",
    "import os\n",
    "\n",
    "subid = '135'\n",
    "\n",
    "full_pipeline(ParticipantData.load_from_file(os.path.join(iposition_directory, 'actual_coordinates.txt'), \n",
    "                                             os.path.join(iposition_directory, '{0}position_data_coordinates.txt'.format(subid)), \n",
    "                                             None), \n",
    "              AnalysisConfiguration(trial_by_trial_accuracy=False), \n",
    "              visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Boundary Analysis\n",
    "\n",
    "Next, we'll look at whether or not context boundary effects were present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_labels = [\"red->blue\", \"blue->red\"]\n",
    "across_triples = [('IceCubeCube', 'PurseCube'), ('BootCube', 'GuitarCube')]\n",
    "within_triples = [('PurseCube', 'BasketballCube'), ('GuitarCube', 'HammerCube')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Context Boundary Effect (CBE) is calculated by taking the average normalized distance between within context and across context pairs in the specified triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as distance\n",
    "\n",
    "cbe_results = {}\n",
    "\n",
    "for sid in test_results:\n",
    "    subject_results = []\n",
    "    for trial in test_results[sid]:\n",
    "        dists = []\n",
    "        for triple in across_triples:\n",
    "            dist = distance.euclidean(trial[triple[0]], trial[triple[1]])\n",
    "            actual_dist = distance.euclidean(correct_locations[triple[0]], correct_locations[triple[1]])\n",
    "            dists.append(dist/actual_dist)\n",
    "        average_across = np.mean(dists)\n",
    "        dists = []\n",
    "        for triple in within_triples:\n",
    "            dist = distance.euclidean(trial[triple[0]], trial[triple[1]])\n",
    "            actual_dist = distance.euclidean(correct_locations[triple[0]], correct_locations[triple[1]])\n",
    "            dists.append(dist/actual_dist)\n",
    "        average_within = np.mean(dists)\n",
    "        cbe = average_across - average_within\n",
    "        subject_results.append(cbe)\n",
    "    cbe_results[sid] = subject_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can be quickly plotted to get means and standard error for each trial as well as for collapsed across trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [cbe_results[k] for k in cbe_results]\n",
    "\n",
    "means = np.mean(data, axis=0)\n",
    "stds = np.std(data, axis=0)\n",
    "stes = [s/np.sqrt(len(data)) for s in stds]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(0, len(means)), means, yerr=stes)\n",
    "plt.figure()\n",
    "plt.bar([0], np.mean(data), yerr=np.std(data)/np.sqrt(len(data)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save/label the data in a DataFrame and then save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame(cbe_results).transpose()\n",
    "df.columns = ['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('context_boundary_effect.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we may want to visualize an exploration path during the task. This can be done using the spatial_navigation_2room visualizer. It can and will take a LONG TIME to run because of the amount of data involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cogrecon.core.visualization.vis_spatial_navigation_2room import visualize\n",
    "import os.path\n",
    "from matplotlib import rc\n",
    "rc('animation', html='html5')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_directory = os.path.join(data_path, '2RoomTestAnonymous', '124')\n",
    "raw_filepath = os.path.join(sub_directory, 'RawLog_Sub124_Trial1_13_15_57_30-05-2017.csv')\n",
    "summary_filepath = os.path.join(sub_directory, 'SummaryLog_Sub124_Trial1_13_15_57_30-05-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "anim = visualize(raw_filepath, summary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
